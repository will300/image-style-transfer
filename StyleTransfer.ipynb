{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleTransfer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vX-gR6vYv9r-",
        "OknXEE2FwOYa",
        "OzTvtIofAlv8",
        "VmD2MPfH8P0y",
        "prRFYfxPwtKk"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX-gR6vYv9r-"
      },
      "source": [
        "# **0. Installations and Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2k3asx_P1r6",
        "outputId": "3b5876b8-cad1-4f99-cc4a-7f31084010d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYyM1G0VP-7H"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMBYaCf_P_nj"
      },
      "source": [
        "!mount --bind /content/drive/My\\ Drive/data /content/data/\n",
        "%cd /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceRzvINbSzs_",
        "outputId": "daf6e2cf-7a0e-4a8c-b2bb-2c1c27895ea8"
      },
      "source": [
        "%cd /usr/local/lib/python3.7/dist-packages/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCONCKgDR5Wt",
        "outputId": "4f0414f4-8619-480f-b6f8-b1ea755b5bc8"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "!pip uninstall fastai\n",
        "!git clone https://github.com/fastai/fastai\n",
        "!pip install -e \"fastai[dev]\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyyaml==5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 10.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 6.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44074 sha256=e013daff6aa97843d94039b652a39559feb201fb5651e0a91f0e7b91a2dc63df\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "Uninstalling fastai-1.0.61:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/fastai-1.0.61.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/fastai/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled fastai-1.0.61\n",
            "Cloning into 'fastai'...\n",
            "remote: Enumerating objects: 13972, done.\u001b[K\n",
            "remote: Counting objects: 100% (173/173), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 13972 (delta 83), reused 115 (delta 52), pack-reused 13799\u001b[K\n",
            "Receiving objects: 100% (13972/13972), 640.08 MiB | 37.08 MiB/s, done.\n",
            "Resolving deltas: 100% (10934/10934), done.\n",
            "Obtaining file:///usr/local/lib/python3.7/dist-packages/fastai\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (19.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (20.9)\n",
            "Collecting fastcore<1.4,>=1.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/98/60404e2817cff113a6ae4023bc1772e23179408fdf7857fa410551758dfe/fastcore-1.3.19-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n",
            "\u001b[?25hCollecting torchvision<0.9,>=0.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (5.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: spacy<3 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.2.4)\n",
            "Collecting torch<1.8,>=1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 21kB/s \n",
            "\u001b[?25hCollecting nbdev<2,>=1.0.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/c8/e2fba530b84a770373a106e4828ea83df62104b9694e367d169e07ea484f/nbdev-1.1.14-py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (7.6.3)\n",
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/0c/e2d52147ac12a77ee4e7fd7deb4b5f334cfb335af9133a0f2780c8bb9a2c/pytorch_lightning-1.2.10-py3-none-any.whl (841kB)\n",
            "\u001b[K     |████████████████████████████████| 849kB 50.0MB/s \n",
            "\u001b[?25hCollecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d3/640f70d69393b415e6a29b27c735047ad86267921ad62682d1d756556d48/pytorch_ignite-0.4.4-py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.4MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 46.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 43.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.4.1)\n",
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/15/df16546bc59bfca390cf072d473fb2c8acd4231636f64356593a63137e55/pydicom-2.1.2-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 47.0MB/s \n",
            "\u001b[?25hCollecting catalyst\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/b6/c0016e849d9c0d58697545c6656ce0d904e703c4d9b1f1ba772bc4d48a2e/catalyst-21.4.1-py2.py3-none-any.whl (482kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 47.5MB/s \n",
            "\u001b[?25hCollecting captum>=0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/b0/8fa3ab89e2e37c960cdd09595fa911fbb8d6da216c8bc98e18c858a0128d/captum-0.3.1-py3-none-any.whl (4.4MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4MB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.1.2)\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/28/4aefc543967839bdb4e139831b82004279f1c435cede2a9557ccf8369875/wandb-0.10.27-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 47.0MB/s \n",
            "\u001b[?25hCollecting kornia\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/b2/8a968f1d7fb1d651a77c1ad7ffce9fc7b4dbd250eecaa9e2f21714fcfb2e/kornia-0.5.0-py2.py3-none-any.whl (271kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.16.2)\n",
            "Collecting neptune-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/d9/9cb3b43a99e84f40803981f88b4d1ff781e775d9140abb22dfe378a5846b/neptune-client-0.9.5.tar.gz (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.1.12)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (4.1.2.30)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.0.0)\n",
            "Collecting ninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai==2.3.1) (2.4.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision<0.9,>=0.8.2->fastai==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.3.1) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.3.1) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.3.1) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.3.1) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.3.1) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai==2.3.1) (1.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (56.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.8,>=1.7.0->fastai==2.3.1) (3.7.4.3)\n",
            "Collecting ghapi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/bf/4085cf4e516591f76b3b367c12b944c85b9321c64590ee030f181d656845/ghapi-0.1.16-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbconvert<6 in /usr/local/lib/python3.7/dist-packages (from nbdev<2,>=1.0.10->fastai==2.3.1) (5.6.1)\n",
            "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from nbdev<2,>=1.0.10->fastai==2.3.1) (5.1.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from nbdev<2,>=1.0.10->fastai==2.3.1) (1.0.0)\n",
            "Collecting fastrelease\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/66/685d5cbd0534395a209ad04afb1573f03467ef3b430b8ee1fec24c332d0c/fastrelease-0.1.11-py3-none-any.whl\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from nbdev<2,>=1.0.10->fastai==2.3.1) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client<=6.1.12 in /usr/local/lib/python3.7/dist-packages (from nbdev<2,>=1.0.10->fastai==2.3.1) (5.3.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastai==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastai==2.3.1) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastai==2.3.1) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastai==2.3.1) (5.0.5)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 40.1MB/s \n",
            "\u001b[?25hCollecting torchmetrics==0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/42/d984612cabf005a265aa99c8d4ab2958e37b753aafb12f31c81df38751c8/torchmetrics-0.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 44.5MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 50.8MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 32.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers->fastai==2.3.1) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->fastai==2.3.1) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->fastai==2.3.1) (3.0.12)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (1.32.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (1.28.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->fastai==2.3.1) (0.36.2)\n",
            "Collecting tensorboardX>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->fastai==2.3.1) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->fastai==2.3.1) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->fastai==2.3.1) (1.1.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.9MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->fastai==2.3.1) (2.3)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 47.9MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->fastai==2.3.1) (5.4.8)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fastai==2.3.1) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fastai==2.3.1) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fastai==2.3.1) (2.4.1)\n",
            "Collecting bravado\n",
            "  Downloading https://files.pythonhosted.org/packages/21/ed/03b0c36b5bcafbe2938ed222f9a164a6c0367ce99a9d2d502e462853571d/bravado-11.0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client->fastai==2.3.1) (3.1.0)\n",
            "Collecting PyJWT\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/9b/8850f99027ed029af6828199cc87179eaccbbf1f9e6e373e7f0177d32dad/PyJWT-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client->fastai==2.3.1) (1.3.0)\n",
            "Collecting websocket-client>=0.35.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[?25hCollecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2,>=1.0.10->fastai==2.3.1) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2,>=1.0.10->fastai==2.3.1) (1.4.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2,>=1.0.10->fastai==2.3.1) (2.6.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2,>=1.0.10->fastai==2.3.1) (3.3.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2,>=1.0.10->fastai==2.3.1) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2,>=1.0.10->fastai==2.3.1) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2,>=1.0.10->fastai==2.3.1) (4.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2,>=1.0.10->fastai==2.3.1) (0.8.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev<2,>=1.0.10->fastai==2.3.1) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev<2,>=1.0.10->fastai==2.3.1) (2.6.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev<2,>=1.0.10->fastai==2.3.1) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev<2,>=1.0.10->fastai==2.3.1) (5.0.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev<2,>=1.0.10->fastai==2.3.1) (5.3.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->nbdev<2,>=1.0.10->fastai==2.3.1) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<=6.1.12->nbdev<2,>=1.0.10->fastai==2.3.1) (22.0.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastai==2.3.1) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastai==2.3.1) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastai==2.3.1) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastai==2.3.1) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastai==2.3.1) (0.7.5)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 35.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->fastai==2.3.1) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->fastai==2.3.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->fastai==2.3.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->fastai==2.3.1) (4.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->fastai==2.3.1) (1.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[?25hCollecting bravado-core>=5.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/11/18e9d28a156c33f2d5f15a5e155dc7130250acb0a569255a2b6b307b596d/bravado_core-5.17.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client->fastai==2.3.1) (1.0.2)\n",
            "Collecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/04/377418ac1e530ce2a196b54c6552c018fdf1fe776718053efb1f216bffcd/simplejson-3.17.2-cp37-cp37m-manylinux2010_x86_64.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 47.1MB/s \n",
            "\u001b[?25hCollecting monotonic\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6->nbdev<2,>=1.0.10->fastai==2.3.1) (0.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->nbdev<2,>=1.0.10->fastai==2.3.1) (1.9.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev<2,>=1.0.10->fastai==2.3.1) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev<2,>=1.0.10->fastai==2.3.1) (0.9.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastai==2.3.1) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastai==2.3.1) (0.7.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning->fastai==2.3.1) (20.3.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 42.3MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 44.6MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->fastai==2.3.1) (0.4.8)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Collecting jsonref\n",
            "  Downloading https://files.pythonhosted.org/packages/07/92/f8e4ac824b14af77e613984e480fa818397c72d4141fc466decb26752749/jsonref-0.2-py3-none-any.whl\n",
            "Collecting swagger-spec-validator>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/09/de/e78cefbf5838b434b63a789264b79821cb2267f1498fbed23ef8590133e4/swagger_spec_validator-2.7.3-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: neptune-client, future, subprocess32, pathtools, imgaug\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.9.5-py2.py3-none-any.whl size=372957 sha256=dc4200c39865eb63f8321c9fcb0d1d26f41162c0d903c8eeb49e3bdfee692b08\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/b1/b8/42228d4e6f34bde7de247c8adcb64fa58c890bed5491e2ec8a\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=06f2d854aa52441cb8645033f4c61bd7d1e938c521b1b43198d4a88f10ac4cb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=79da737a7dcbafb19bf77d5fc6341a6c3de114e004e33bd4a9e4a3b375eb97f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=7c43ee26efaab7c41ce1484076f133cacddccb91b9293be5dd55cb761533fb44\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp37-none-any.whl size=654019 sha256=789cc14ea26a7d499ec513322b1a0f1d1eabef91946765a377693846bfa90c51\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built neptune-client future subprocess32 pathtools imgaug\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fastcore, torch, torchvision, ghapi, fastrelease, nbdev, future, torchmetrics, multidict, yarl, async-timeout, aiohttp, fsspec, pytorch-lightning, pytorch-ignite, tokenizers, sacremoses, transformers, sentencepiece, pydicom, tensorboardX, catalyst, captum, shortuuid, subprocess32, sentry-sdk, configparser, smmap, gitdb, GitPython, docker-pycreds, pathtools, wandb, kornia, jsonref, swagger-spec-validator, simplejson, bravado-core, monotonic, bravado, PyJWT, websocket-client, neptune-client, ninja, fastai, imgaug\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Running setup.py develop for fastai\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed GitPython-3.1.14 PyJWT-2.0.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 bravado-11.0.3 bravado-core-5.17.0 captum-0.3.1 catalyst-21.4.1 configparser-5.0.2 docker-pycreds-0.4.0 fastai fastcore-1.3.19 fastrelease-0.1.11 fsspec-2021.4.0 future-0.18.2 ghapi-0.1.16 gitdb-4.0.7 imgaug-0.2.6 jsonref-0.2 kornia-0.5.0 monotonic-1.6 multidict-5.1.0 nbdev-1.1.14 neptune-client-0.9.5 ninja-1.10.0.post2 pathtools-0.1.2 pydicom-2.1.2 pytorch-ignite-0.4.4 pytorch-lightning-1.2.10 sacremoses-0.0.45 sentencepiece-0.1.95 sentry-sdk-1.0.0 shortuuid-1.0.1 simplejson-3.17.2 smmap-4.0.0 subprocess32-3.5.4 swagger-spec-validator-2.7.3 tensorboardX-2.2 tokenizers-0.10.2 torch-1.7.1 torchmetrics-0.2.0 torchvision-0.8.2 transformers-4.5.1 wandb-0.10.27 websocket-client-0.58.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OknXEE2FwOYa"
      },
      "source": [
        "#**1. Style Transfer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpDBhVIsQFXz"
      },
      "source": [
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image, ImageFile\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torchvision.models import vgg19_bn, resnet18\n",
        "from torchvision.models.resnet import BasicBlock\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose, Resize as TResize\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import AvgPool2d, Conv2d, Module, Sigmoid\n",
        "from torchvision.utils import save_image\n",
        "from fastai.data.block import DataBlock\n",
        "from fastai.callback.schedule import fine_tune\n",
        "from fastai.vision.learner import unet_learner, create_body\n",
        "from fastai.vision.data import ImageBlock\n",
        "from fastai.vision.augment import Resize, RandomCrop, setup_aug_tfms\n",
        "from fastai.vision.models.unet import DynamicUnet\n",
        "from fastai.data.transforms import get_image_files, RandomSplitter, parent_label\n",
        "from fastai.data.block import RegressionBlock\n",
        "from fastai.torch_core import flatten_check, TensorImage, Module\n",
        "from fastai.metrics import mse, accuracy\n",
        "from fastai.layers import PixelShuffle_ICNR, ConvLayer, SigmoidRange\n",
        "from fastai.learner import Learner\n",
        "from sys import getsizeof\n",
        "from inspect import getsource\n",
        "from pathlib import Path\n",
        "from types import MethodType\n",
        "from collections.abc import Iterable\n",
        "from matplotlib import pyplot as plt\n",
        "from math import ceil\n",
        "from enum import Enum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjqgrNgXwNmH"
      },
      "source": [
        "%cd /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXSBus9KQH5o"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg_net = vgg19_bn(pretrained=True, progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udlxVhz7Fqwc"
      },
      "source": [
        "style_net = vgg_net.features\n",
        "style_net.to(device)\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZitP-O6c7cY"
      },
      "source": [
        "def create_gram_array(self, layer):\n",
        "\n",
        "    indices = torch.combinations(torch.range(0, layer.size()[1] - 1)).to(device).to(torch.int64)\n",
        "    filter_i = torch.index_select(layer, 1, torch.flatten(indices[:, 0]))\n",
        "    filter_j = torch.index_select(layer, 1, torch.flatten(indices[:, 1]))\n",
        "    #arr = torch.einsum(\"ijkl,ijkl->ij\", filter_i, filter_j)\n",
        "    arr = torch.sum(filter_i*filter_j, (2, 3))\n",
        "    #print(\"Gram array: \", arr.size())\n",
        "    return arr\n",
        "\n",
        "style_net.create_gram_array = MethodType(create_gram_array, style_net)\n",
        "style_net.switch = 0\n",
        "\n",
        "transf = TResize((512, 512))\n",
        "def forward(self, input):\n",
        "    input = transf(input)\n",
        "    layer_nums = {1, 8, 15, 28, 41} if self.switch == 0 else {28}\n",
        "    output = None\n",
        "    for l, module in enumerate(self):\n",
        "        if (input.device.type == \"cpu\" and device.type == \"cuda\") or \\\n",
        "           (input.device.type == \"cuda:0\" and device.type == \"cpu\"): \n",
        "            input = input.float().to(device)\n",
        "        input = module(input)\n",
        "        if l in layer_nums:\n",
        "            if self.switch == 0:\n",
        "                gram_array = self.create_gram_array(input)        \n",
        "                output = gram_array if type(output) == type(None) else \\\n",
        "                torch.hstack((output, gram_array))\n",
        "            else:\n",
        "                output = torch.flatten(input, 1)\n",
        "    return output\n",
        "    \n",
        "style_net.forward = MethodType(forward, style_net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtDyoSwOqsHA"
      },
      "source": [
        "dir = 'data/images'\n",
        "path = Path(dir)\n",
        "BATCH_SIZE = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRvgwZPrqufo"
      },
      "source": [
        "## Dataset preparation: Only needed once per dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vWS0s_13Y0L"
      },
      "source": [
        "Generate the grams for the style image and save to a tensor file, to avoid having to recalculate it on each pass through the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZX1Qnx8quCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2316f4-fb62-43dd-8cf0-4f9df6ae3d5b"
      },
      "source": [
        "# This is the point to swap in a different style image\n",
        "# Currently using Starry Night by Van Gogh jpeg\n",
        "img = Image.open(\"starry.jpg\")\n",
        "img = img.resize((512, 512))\n",
        "arr = np.asarray(img) / 255\n",
        "style_tensor = TensorImage(arr).permute(2, 0, 1).unsqueeze(0)\n",
        "style_batch = torch.cat((style_tensor,)*BATCH_SIZE, dim=0).float()#.to(device)\n",
        "style_net.switch = 0\n",
        "with torch.no_grad():\n",
        "    with torch.cuda.amp.autocast():\n",
        "        targ_style = style_net(style_batch)\n",
        "        torch.save(targ_style, \"starry_night.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7VLyktH4SS6"
      },
      "source": [
        "Do the same for each image in the training set and save to a numpy file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs0yckBlq1LO"
      },
      "source": [
        "#os.mkdir(dir + \"_tensors\")\n",
        "style_net.switch = 1\n",
        "with torch.no_grad():\n",
        "    with torch.cuda.amp.autocast():\n",
        "        for filename in os.listdir(dir):\n",
        "            dest = dir + \"_tensors/\" + filename[:-4] + \".npy\"\n",
        "            img = Image.open(dir + \"/\" + filename)\n",
        "            arr = np.asarray(img) / 255\n",
        "            tensor = TensorImage(arr).permute(2, 0, 1).unsqueeze(0)\n",
        "            output = style_net(tensor).cpu().numpy()\n",
        "            np.save(dest, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT30_on5pUaS"
      },
      "source": [
        "### Autoencoder Label Getter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADCSlc-n0LQo"
      },
      "source": [
        "# Mapping from filename to pixelmaps for autoencoder priming\n",
        "def get_labels(o):\n",
        "    img = cv2.imread(str(o))\n",
        "    arr = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    tensor = torch.from_numpy((arr/255)).float()\n",
        "    dims = tensor.size()\n",
        "    tensor = tensor.permute(2, 0, 1)#.unsqueeze(0)\n",
        "    return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6OJCzp4pZcG"
      },
      "source": [
        "### Main Model Label Getter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slkbodIKops7"
      },
      "source": [
        "# Mapping from filename to gram arrays for full training\n",
        "def get_labels(o):\n",
        "    path = str(o.parent) + \"_tensors/\" + str(o.name[:-4]) + \".npy\"\n",
        "    arr = np.load(path)\n",
        "    return torch.from_numpy(arr).squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf0lnmCF-oUe"
      },
      "source": [
        "### Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dpg5k3v0Okk"
      },
      "source": [
        "pics = DataBlock(\n",
        "    blocks=(ImageBlock, RegressionBlock), \n",
        "    get_items=get_image_files, \n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=get_labels)\n",
        "\n",
        "dls = pics.dataloaders(path, bs=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnPLUqQz-rIn"
      },
      "source": [
        "### Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAkMeLzKj9og"
      },
      "source": [
        "targ_style = torch.load(\"starry_night.pt\")\n",
        "\n",
        "# Loss function for full network\n",
        "def style_and_structure_mse(inp, targ_struct):\n",
        "\n",
        "    # Input to the loss function is a tuple containing a structure feature stack\n",
        "    # and a set of 5 style gram arrays concatenated together \n",
        "  \n",
        "    loss = F.mse_loss(inp[0], targ_struct)*1e1\n",
        "\n",
        "    idxs = [2016, 8128, 32640, 130816, 130816]\n",
        "    i1, i2, i3, i4, i5 = torch.split(inp[1], idxs, dim=1)\n",
        "    s1, s2, s3, s4, s5 = torch.split(targ_style, idxs, dim=1)\n",
        "    sl1 = F.mse_loss(i1, s1)\n",
        "    sl2 = F.mse_loss(i2, s2)\n",
        "    sl3 = F.mse_loss(i3, s3)\n",
        "    sl4 = F.mse_loss(i4, s4)\n",
        "    sl5 = F.mse_loss(i5, s5)\n",
        "\n",
        "    # Style loss produces much larger numbers than the structural MSE and\n",
        "    # is reduced appropriately \n",
        "\n",
        "    style_loss = sl1*2e-7 + sl2*2e-6 + sl3*2e-5 + sl4*2e-4 + sl5*2e-3\n",
        "\n",
        "    #print(loss.item(), sl1.item(), sl2.item(), sl3.item(), sl4.item(), sl5.item())\n",
        "    \n",
        "    loss += style_loss\n",
        "    return loss\n",
        "    #return style_loss\n",
        "\n",
        "# Loss function for autoencoder priming\n",
        "def autoencoder_mse(inp, targ):\n",
        "    tform = TResize((inp.size()[-2], inp.size()[-1]))\n",
        "    targ = tform(targ)\n",
        "    return F.mse_loss(inp, targ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z860D3C_LVK0"
      },
      "source": [
        "### Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAWicb2lm3Pk"
      },
      "source": [
        "### Training the UNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOoB1oKdm-aX"
      },
      "source": [
        "#learn = unet_learner(dls, arch=resnet18, n_out=3, y_range=[0, 1], loss_func=autoencoder_mse)\n",
        "learn = unet_learner(dls, arch=resnet18, n_out=3, y_range=[0, 1], loss_func=style_and_structure_mse)\n",
        "\n",
        "# Remove the residual connection on the highest layer of the UNet\n",
        "def forward(self, up_in):\n",
        "    up_out = self.shuf(up_in)\n",
        "    return self.conv2(self.conv1(self.relu(up_out)))\n",
        "\n",
        "learn.model[7].forward = MethodType(forward, learn.model[7])\n",
        "learn.model[7].conv1[0] = Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szgQ0nTLCQ8d"
      },
      "source": [
        "Only run the following cell when training the full model, not when priming the autoencoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckgmLZsTrKvy"
      },
      "source": [
        "learn.model = torch.nn.Sequential(learn.model, style_net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9pwOvlw_e__"
      },
      "source": [
        "### Loading Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0rzeyTQ8HDb"
      },
      "source": [
        "Load the vanilla autoencoder weights if initial priming is finished but yet to start full model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzMWnQYAA36W"
      },
      "source": [
        "checkpoint = torch.load(\"snipped_unet.pth\")\n",
        "learn.model[0].load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ9h6WNJ8S_9"
      },
      "source": [
        "Load the model weights if resuming full training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHE3OkS_ORHB"
      },
      "source": [
        "checkpoint = torch.load(\"snipped_unet_starry.pth\")\n",
        "learn.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "learn.model.to(device)\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-PnPJLR_pMR"
      },
      "source": [
        "### Forward Method and Optimizer & Training Steps\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW_yyLut0j7c"
      },
      "source": [
        "# Modified version\n",
        "def forward(self, x):\n",
        "    torch.cuda.empty_cache()\n",
        "    res = x\n",
        "    #noise_tensor = TensorImage(torch.randn(*x.size())).float().to(device)\n",
        "    #res = noise_batch\n",
        "    #for l in self.layers:     \n",
        "    for l in self: \n",
        "        #print(f\"Bytes Allocated {torch.cuda.memory_allocated()}\\n\")\n",
        "        #print(torch.cuda.memory_summary(device=device))\n",
        "        #print(torch.cuda.list_gpu_processes(device=device))\n",
        "        res.orig = x\n",
        "        #res.orig = noise_tensor\n",
        "        if not isinstance(l, DynamicUnet):\n",
        "            l.switch = 0 \n",
        "            self.stored = res\n",
        "            \n",
        "        nres = l(res)\n",
        "        # We have to remove res.orig to avoid hanging refs and therefore memory leaks\n",
        "        res.orig, nres.orig = None, None\n",
        "        res = nres\n",
        "\n",
        "        if not isinstance(l, DynamicUnet):\n",
        "            style = res\n",
        "            l.switch = 1\n",
        "            structure = l(self.stored)\n",
        "            del self.stored\n",
        "\n",
        "    #del noise_tensor\n",
        "    return structure, style\n",
        "    \n",
        "learn.model.forward = MethodType(forward, learn.model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sriShthQ8n7q"
      },
      "source": [
        "The following two cells help convert tensor values to 16-bit half types to reduce memory and stop the GPU from becoming overloaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXB3RLG3bpbQ"
      },
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "class OptState(Enum):\n",
        "    READY = 0\n",
        "    UNSCALED = 1\n",
        "    STEPPED = 2\n",
        "\n",
        "def step(self, model):\n",
        "\n",
        "    if (not self._enabled):\n",
        "        model._with_events(model.opt.step, 'step', CancelStepException)\n",
        "        return\n",
        "\n",
        "    #if \"closure\" in kwargs:\n",
        "    #    raise RuntimeError(\"Closure use is not currently supported if GradScaler is enabled.\")\n",
        "\n",
        "    self._check_scale_growth_tracker(\"step\")\n",
        "\n",
        "    optimizer_state = self._per_optimizer_states[id(model.opt)]\n",
        "\n",
        "    if optimizer_state[\"stage\"] is OptState.STEPPED:\n",
        "        raise RuntimeError(\"step() has already been called since the last update().\")\n",
        "\n",
        "    retval = None\n",
        "\n",
        "    if (hasattr(model.opt, \"_step_supports_amp_scaling\") and model.opt._step_supports_amp_scaling):\n",
        "        # it can query its own state, invoke unscale_ on itself, etc\n",
        "        model._with_events(model.opt.step, 'step', CancelStepException)\n",
        "        optimizer_state[\"stage\"] = OptState.STEPPED\n",
        "        return\n",
        "\n",
        "    if optimizer_state[\"stage\"] is OptState.READY:\n",
        "        self.unscale_(model.opt)\n",
        "\n",
        "    #assert len(optimizer_state[\"found_inf_per_device\"]) > 0, \"No inf checks were recorded for this optimizer.\"\n",
        "\n",
        "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
        "        model._with_events(model.opt.step, 'step', CancelStepException)\n",
        "        return\n",
        "\n",
        "    optimizer_state[\"stage\"] = OptState.STEPPED\n",
        "\n",
        "scaler.step = MethodType(step, scaler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNWEjaL0zD1e"
      },
      "source": [
        "CancelStepException = \"\"\n",
        "def _do_one_batch(self):\n",
        "    #print(\"1 \", next(iter(self.model.parameters()))[0, 0, 0])\n",
        "    with torch.cuda.amp.autocast(): #\n",
        "        self.pred = self.model(*self.xb)\n",
        "        self('after_pred')\n",
        "        if len(self.yb):\n",
        "            self.loss_grad = self.loss_func(self.pred, *self.yb)\n",
        "            self.loss = self.loss_grad.clone()\n",
        "        self('after_loss')\n",
        "        if not self.training or not len(self.yb): return\n",
        "        self('before_backward')\n",
        "    scaler.scale(self.loss_grad).backward() # \n",
        "    scaler.unscale_(self.opt)\n",
        "    scaler.step(self)\n",
        "    #self._with_events(self.opt.step, 'step', CancelStepException)\n",
        "    scaler.update() #\n",
        "    self.opt.zero_grad()\n",
        "    del self.pred, self.xb\n",
        "\n",
        "learn._do_one_batch = MethodType(_do_one_batch, learn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwAG05bKAFFH"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKR8NV6_QXWW"
      },
      "source": [
        "# Use for either autoencoder priming or full model training\n",
        "# changing the number of epochs as appropriate\n",
        "num_epochs = 120\n",
        "learn.fine_tune(num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmqmPKLzNLEU"
      },
      "source": [
        "Save the autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fswmhe0TNO2F"
      },
      "source": [
        "torch.save({'model_state_dict': learn.model.state_dict(), \n",
        "            'optimizer_state_dict': learn.opt.state_dict()}, \"snipped_unet.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vX-1IP2NIWA"
      },
      "source": [
        "Save the full model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgGQmfPxMwbK"
      },
      "source": [
        "torch.save({'model_state_dict': learn.model.state_dict(), \n",
        "            'optimizer_state_dict': learn.opt.state_dict()}, \"snipped_unet_starry.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIky9w81AIXc"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X0tYM2qoUjm"
      },
      "source": [
        "x, y = dls.train.one_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fcuNJaRIF8L"
      },
      "source": [
        "img = Image.open(\"starry.tif\")\n",
        "img = img.resize((512, 512))\n",
        "arr = np.asarray(img) / 255\n",
        "tensor = TensorImage(arr).permute(2, 0, 1)\n",
        "save_image(tensor, \"starry_resized.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-s2igJJNPPl"
      },
      "source": [
        "save_image(x, \"orig8.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTU446WH50JX"
      },
      "source": [
        "#learn.model.eval()\n",
        "#save_image(x.squeeze(0), \"prestarrified.jpg\")\n",
        "#save_image(y[0].squeeze(0), \"target.jpg\")\n",
        "with torch.cuda.amp.autocast():\n",
        "    res = learn.model[0](x)\n",
        "    save_image(res[0].squeeze(0), \"snipped_unet8.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}